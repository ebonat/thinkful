{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost guided example\n",
    "\n",
    "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface.  But they aren't quite a black box.  We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAEWCAYAAAAEtVmdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH4JJREFUeJzt3Xu8XPO9//HXWxK5X0RSQkPQlEbkhERwThCVOgTFQaPl\n16QckdNqUKp+p6eVUndttag0/BxRt7pTWpeSHIQgkTuCkBwlaEIikQhJPr8/vt9hZTKz9+y9Z61Z\ne/s8H495ZGZdvzOZz/6uteazPl+ZGc65dGxW6wY415J5gDmXIg8w51LkAeZcijzAnEuRB5hzKfIA\ny4Ck7SStktSqgmWHSfp7HfNvkPTL6rbQpcUDrIikhySdV2L6EZLekdS6ods0s/81s05mtr46rWwc\nSSbpK7VsQ4GkRZKG17odafMA29Qk4ARJKpr+f4CbzWxdQzbWmIBsyb5on4cH2KbuBbYE9i1MkLQF\ncBhwY3x9qKSZkj6U9Kak8Yll+8Se4iRJ/ws8npjWOi7zPUkvSVop6XVJpxQ3QtJ/Sloa/9IfX66x\nkg6TNEvScklPSxpQyZuUNF7SHZJuiu2YK+mrkv6vpPfi+zoosfwUSRdJei6+7/skdU/M/6ak+bEd\nUyR9LTFvkaSfSJoDfCTpVmA74M/x0PnsuNwd8ShhhaQnJO2a2MYNkq6W9GBs77OSdkrM31XSo5Le\nl/SupP+M0zeTdI6khZKWSbo92e7UmZk/ih7AtcB1idenALMSr4cBuxH+QA0A3gWOjPP6AEYIxo5A\n+8S01nGZQ4GdAAH7A6uBPRLbXgf8Gmgb538E7Bzn3wD8Mj7fHXgP2AtoBYwCFgFty7wvA74Sn48H\nPgb+FWgd2/sG8FOgDXAy8EZi3SnAW0D/+L7uAm6K874a2/iNuO7ZwGvA5nH+ImAW0Bton5g2vKh9\nJwKd4/u+ougzvwFYBgyJ7b0ZuC3O6wwsAc4E2sXXe8V5pwHTgC/H7f4BuDWz71Ktv8x5fABDgeVA\nu/h6KnBGHctfAfymKMB2TMzfKMBKrH8vcFp8Xgiwjon5twM/S3zRCgF2DXB+0bYWAPuX2U9xgD2a\nmHc4sApoZZ9/aQ3oFl9PAS5OLN8P+IQQ2D8Dbk/M2ywG47D4ehFwYlFbNgmwovnd4v67Jt538o/e\nCODl+PzbwMwy23kJODDxuhfwabn/i2o//BCxBDN7ClgKHBkPQ4YAtxTmS9pL0mRJ/5C0AhgL9Cja\nzJvlti/pEEnT4uHMcsKXJbn+B2b2UeL1YmCbEpvaHjgzHpYtj9vqXWbZUt5NPF8DLLXPL8Ssif92\nSiyTfE+LCb1Vj7i/xYUZZrYhLrttmXU3IamVpIvjodyHhACEjT+XdxLPVyfa1htYWGbT2wP3JD6f\nl4D1wFZ1tadaPMDKuxH4LnAC8LCZJb+MtwD3A73NrCswgXC4l1TyNgVJbQmHV5cDW5lZN+AvRetv\nIalj4vV2wNslNvcmcIGZdUs8OpjZrRW/y4bpXdSmTwl/iN4mfJEBiBeIehN6sYLiz6P49XeAI4Dh\nQFdCrw+bfq6lvAnsWMe8Q4o+o3Zm9laZ5avKA6y8Gwn/2ScTriwmdQbeN7OPJQ0hfDkqtTnhXOAf\nwDpJhwAHlVjuF5I2l7Qv4QLLHSWWuRYYG3tUSeoYL8B0bkB7GuIESf0kdQDOA+6MPd7twKGSDpTU\nhnAutBZ4uo5tvcvGQdE5rrMM6ABc2IB2PQD0knS6pLaSOkvaK86bAFwgaXsAST0lHdGAbTeJB1gZ\nZraI8AXpSOitkr4PnCdpJfBzwhes0u2uBMbFdT4gBGfx9t+J894mnMyPNbOXS2xrOuEPwFVx+deA\n0ZW2pRH+SDgXeodwMWFcbMcCQk9/JaFHOxw43Mw+qWNbFwH/FQ/dziL8QVtM6PVeJFyYqEj8TL8R\n9/sO8CpwQJz9W8Ln+0j8/5pGuCiUCcUTP+fqJGkK4arhdbVuS3PiPZhzKfIAcy5FfojoXIq8B3Mu\nRS028bJHjx7Wp0+fWjfDtVAzZsxYamY961uuxQZYnz59mD59eq2b4VooSYvrX8oPEZ1LlQeYcyny\nAHMuRR5gzqXIA8y5FHmAOZciDzDnUuQB5lyKWuwPzXPfWkGfcx6sdTNcM7bo4kObvA3vwZxLkQeY\ncynyAHMuRakGmKR7Jc2IFV/HxGknSXolVn+9VtJVcXpPSXdJej4+/iVOHyLpGYVKuk9L2jnNNjtX\nTWlf5DjRzN6X1B54XtKDhCKVewArgceB2XHZ3xKKdz4laTvgYeBrwMvAvma2TmGwgAuBo0vtLAbx\nGIBWXeq9k8C51KUdYOMkHRWf9yYMoPA/ZvY+hFrkhLLLEEqk9dPnYy50kdSJUCNvkqS+hFp6bcrt\nzMwmAhMB2vbq67dqu5pLLcAkDSMEzT5mtjpWJXqZ0CuVshmwt5l9XLSdq4DJZnaUpD6EEs7ONQtp\nnoN1JZSAXi1pF2BvQo3B/SVtoTDSSPJQ7xHgh4UXkgYmtlOowjo6xfY6V3VpBthDQOs4ZM35hIKP\nbxHOoZ4F/kYoMLkiLj8OGCxpjqQXCfXeAS4FLpI0lTDQgHPNRuZVpSR1MrNVsQe7B7jezO6p9n4G\nDx5sXjLApUXSDDMbXN9ytfgdbLykWcA8wnhU99agDc5lIvNcRDM7K+t9Olcrnuzr6lSNhNcvMk+V\nci5FVQkwhUG+51VjW861JN6DOZeiagZYq5i8O1/SI5LaSzo5Ju7Ojom8HQAk3SBpgqQnY+LvYXH6\naEn3SXpI0gJJ58bp50k6vbAjSRdIOq2KbXcuFdUMsL7A1Wa2K7CckKVxt5ntaWb/RBh8+qTE8n2A\n/YFDgQmS2sXpQ4DjgYHAsZIGA9cTxktG0mbAccBNxQ2QNEbSdEnT169eUTzbucxVM8DeMLNZ8fkM\nQgD1j73UXELQ7JpY/nYz22BmrwKvA7vE6Y+a2TIzWwPcDQyNw7kuk7Q7YTzjmWa2rLgBZjbRzAab\n2eBWHbpW8a051zjVvEy/NvF8PdCeMJ7vkWY2W9JoYFhimXKjzpebfh0hF3FrQo/mXO6lfZGjM7Ak\njjx/fNG8YyVtJmknwmjzC+L0b0jqHu8hOxKYGqffAxwM7Em4V8y53Ev7h+afERJ7FwNzCQFXsAD4\nH2ArYKyZfRzvBXuKMJr9V4BbzGw6gJl9ImkysNzM1qfcbueqoioBFs+R+ideX56YfU2Z1aaa2Rkl\npr9nZqcWT4wXN/YGjq2kTbtt25XpnoXgaqxZ/A4mqR/wGvBYvCjiXLPQYgdBb9urr/UadUWtm1Ex\nz/lrXvJ8u4pzXxhpl23rJun79SwzUNKICrY1TNI/V691zqUv7R6sG1BngBEyNuoNMMJvaB5grllJ\nO8AuBnaSNEvSHZI+O9GI+YjfAs4DRsZlRsbfwO6NtTmmSRoQq0mNBc6Iy+2bcrudq4q0fwc7B+hv\nZgNjfcRvAQ9K2hw4EPgPoAMwuHBpXtKVhFSoIyV9Hbgxrj8BWFX0E8BGvPCoy5ssL3L8FThAUlvg\nEOCJmG9YbCjhh2bM7HFgS0ldKtmB5yK6vMkswGJB0SnAvwIjgT9ltW/naiXtAFvJxulRfwK+B+xL\nqJtYapkniXmLsTrwUjP7sMRyzuVeqgEWbymZKmmepMsI1Xv3B/5mZp/ExSYTatLPkjQSGA8MigVL\nLwZGxeX+DBzlFzlcc9JiMzm88KhLk2dyOJcDHmDOpcgLj+aAJ/q2XN6DOZeiTANM0nhJZ8XnoyVt\n08D1PeHXNSu17MFGAyUDTFK5ccCG4Qm/rhlpUoDFktkvS5oUk3PvlNRB0iJJl0h6Lj6+UrTeMcBg\n4Ob4u1b7uM7PJT1FKIgzTtKLcbu3ecKva46qcZFjZ+AkM5sq6Xo+vz3lQzMbIum7wBXAYYUVzOxO\nSacCZxWK2sSCNx+b2dD4+m1gBzNbK6mbmS2vL+HXk31d3lTjEPFNMyuUVruJkKwLcGvi330q3FYy\nP3EOoYc7AVhXycqe7OvyphoBVkkB0UrTRT5KPD8UuBoYBMyIQ84616xUI8C2k1Toob5DqGsIIWO+\n8O8zJdYrm7wbS7T1NrPJwNmEO6M71bWOc3lUjQB7GRgVk3O34PM6iG0lPQucBpSqf3gDYdCHWbGK\nb1Ir4KZY034m8BszW44n/LpmpknJvvHK3gNm1r9o+iLCXcpLm9K4pvBkX5cmT/Z1Lgda7O0qeS88\n6vmHzZv3YM7lQC1zEXeJFytmxiGMyq3zF0ndsmulc9VTyx7sSOA+M9vdzBaWW8jMRsQriJ9R4L2v\ny71a5SKOAE4H/j2O+UUsNjpDYRD1MYllF0nqEff1kqTfAy8AvZvSdueyUI1eYGdgopkNAD6kKBcR\nuIqQi/gZM/sLMIHw+9YBcfKJZjaIkAQ8TtKWZfZ1Y+z1FhfPlA+C7nImT7mI4yTNBqYReqe+JZZZ\nbGbTym3AcxFd3lQjv6/JuYix/uFwYB8zWy1pCtCuxKIflZjmXG7VMhcxqSvwQQyuXQhDxTrX7NUy\nFzHpIaB13Mb5hMNE55o9z0V0rhE8k8O5HGjSRQ4zWwT0LzG9T1O261xL0WLvEq5l4VFP5HUFfojo\nXIpyH2CSpkiq92TSuTzKfYCVU0dxUudyI5NzMEk/I4xa+SawFJhBqJP4LHAAoajNSWb2ZKzP8d9A\nP+AloH1iO6uAXxOGoT2Tz3/Udi6XUg8wSXsCRwMDgTaETPgZhf3H4qQjgHMJ6VL/Aaw2swGSBsTl\nCzoC88zs52X25YVHXa5kcYj4L4T7vj42s5WEylAFd8d/ZwB94vP9CEnDmNkcQgHSgvXAXeV25Mm+\nLm9qfQ62Nv67nsp604/NbH2K7XGuqrIIsKnA4ZLaSepEqNhblycIScNI6g8MSLl9zqUm9XMwM3te\n0v3AbGARMB2o627Ia4D/jom/s4Dn0m6jc2nJpGybpE5mtkpSB0IPNcbMXqhvvabwZF+XpkqTfbNK\nlZooqR/hJspJaQeXc3mRSYCZ2Xey2E9SVrmInnfo6lLrq4jOtWg1CbCiAqQlcw3jgOcPZN8656rH\nezDnUlSVAGtsAdKEY+P8V0qN+xV7vD9KelzSq5JOrka7nUtbNXuwBhcgTWgdlzmdkJNYygDCj9T7\nAD+XtE3xAl541OVNNQOsKQVIS+UkFrvPzNbEQjqTgSHFC3guosubagZYUwqQVpKTWG77zuVWNQOs\nGgVI63JEzGfcEhgGPN+EbTmXiWoGWDUKkNblOeBBQlHS883s7aY01rksVCUXMe0CpJLGA6vM7PJK\n1/FcRJcmLzzqXA5UJRcx7QKkZja+GttxLmteeLSJPNnX1cUPEZ1LUdUCLIvkXElHxvvKnGsWmlsP\ndiShXqJzzUK952CSOgK3A18GWhEGyHsd+C2hTuFa4MCidcYDOwC9gK8CPyKMWnkI8BZwuJl9KmkQ\noZBoJ0JB0tFmtkTSTsDVQE9gNXAy0B34JrC/pP8CjjazhU15886lrZKLHAcDb5vZoQCSugIzgZGx\noE0XYE2J9XYiVO3tR8jgONrMzpZ0D3CopAeBK4EjzOwfkkYCFwAnAhOBsWb2qqS9gN+b2ddj8ZwH\nzOzOUg31wqMubyoJsLnAryRdAjwALAeWmNnzAGb2IYCk4vX+GnupuYSe76HE9voQsu/7A4/GdVsB\nS2Jpt38G7khss20lb8bMJhKCk7a9+nquoqu5egPMzF6RtAcwArgIeLTCba+N62+Q9Kl9njKyIe5X\nwHwz2yjDPvaIy81sYIX7cS636r3IEe+7Wm1mNwGXA3sBvWLNeSR1ltSY39MWAD0LCcKS2kjaNfaI\nb0g6Nk6XpH+K66wEOjdiX87VRCWBsRtwmaQNwKeEwRkEXBlHQllDGLShQczsE0nHAL+L53WtCTdk\nzieMxHJNvJjRBriNULj0NuBaSeOAY/wih8u7TAqP1oIn+7o0ebKvcznguYgN4HmHrqG8B3MuRZkH\nWFNyFiWdHgeQcK5ZaG492OmAB5hrNqp2DtbInMUhcX47wuX+75nZAkmtgEsIaVobgGsJPw1sA0yW\ntNTMDqhW251LSzUvcjQmZ/FlYF8zWydpOHAhYcD0MYR0qoFxXncze1/Sj4ADytX48FxElzfVDLDG\n5Cx2BSZJ6kuoc9gmTh8OTDCzdXHd9ytpgOciuryp2jmYmb0C7EEItIuAf6tgtfOBybEa1eGEQ0Xn\nWoxq3tHcmJzFroT7wwBGJ6Y/CpxSWF5S9zjdcxFds1LNQ8TG5CxeSjhE/BHweGL6dYQbNedI+pRw\nkeMqwuHfQ5Le9oscrjnwXETnGsFzEZ3LAQ8w51Lkyb4V8CRf11jegzmXolwFmKT1kmYlHufE6YdJ\nmilptqQXJZ1S67Y6V4m8HSKuKS52I6kN4fL8EDP7u6S2lB9m1rlcyVuAldKZ0M5lAGa2llAwx7nc\ny9UhItC+6BBxZMxDvB9YLOlWScdLKtluSWMkTZc0ff3qFdm23LkS8taDbXKICGBm/y5pN0ImyFnA\nN9g4taqwnCf7ulzJWw9WlpnNNbPfEILr6Fq3x7lK5D7AJHWSNCwxaSCwuEbNca5B8naI2F7SrMTr\nhwgDQpwt6Q+EhOGPKHF46Fwe5SrAzKxVmVkjGrqt3bbtynTPwHA1lvtDROeas1z1YNXU0FxEzzd0\nafAezLkU1TzAJJmkXyVenxWHoC28HiPp5fh4TtLQmjTUuUaoeYAR6iX+m6QexTMkHQacAgw1s12A\nscAtkrbOuI3ONUoeAmwdIfvijBLzfgL8uFAH0cxeACYBP8iuec41Xh4CDOBq4PhYrDRpV2BG0bTp\ncfomPBfR5U0uAiwWJb0RGNfE7Uw0s8FmNrhVh+JYdS57uQiw6ArgJEId+4IXgUFFyw0iDDPrXO7l\nJsDibSm3E4Ks4FLgEklbAkgaSEiT+n3mDXSuEfL2Q/OvgFMLL8zsfknbAk9LMkJl3xPMbEmtGuhc\nQ3jhUecawQuPOpcDHmDOpShv52BVU1+yryf3uix4D+ZcinLTg8X8wiuAPQn5iYuAh4HvJRZrTcji\n6GdmL2XdRucaKhcBpjCu7D3AJDM7Lk4bCHQ2s98mlrsQmOXB5ZqLXAQYcADwqZlNKEwws2RtDiTt\nB3yLMEytc81CXs7B+rNpUu9nJHUDbgBGFQZTL7OcJ/u6XMlLgNVnAvBHM5ta10Ke7OvyJi8BNp9N\nk3oBkDQK2B44P9MWOVcFeQmwx4G2ksYUJkjaU9L+wIXA8Wa2rmatc66RcnGRw8xM0lHAFZJ+AnxM\nuEzfDugA3B0uNH7mh2b2ZOYNda6BPNnXuUbwZF/nciAXh4hp8FxElwfegzmXotwEmKStJd0maWEc\n6Pwvkr4qaV7RcuMlnVWrdjrXELk4RKwjF3GrmjbMuSbKSw9WLhfxzdo1ybmmy0UPRt25iDsVDcq3\nNXB5qQXjD9VjAFp16VnVBjrXGHkJsLosTA6MnhwYopgPgu7yJi+HiGVzEZ1rzvISYCVzEQlJvs41\nW7kIMAv5WkcBw+Nl+vnAeODtmjbMuSbyXETnGsFzEZ3LAQ8w51LUHC7TN0pdyb6e6Ouy4j2Ycyny\nAHMuRc02wCS1qnUbnKtPJgEm6TxJpydeXyDpNEk/lvS8pDmSfpGYf6+kGZLmF/34vCpu61lgnyza\n7lxTZNWDXQ98F0DSZsBxwDtAX2AIMBAYFKv3ApxoZoOAwcC4whCyhPGb55nZXmb2VPFOvPCoy5tM\nriKa2SJJyyTtTrjHayZhkIeD4nOAToSAe4IQVEfF6b3j9GXAeuCuOvbjyb4uV7K8TH8dYQDzrQk9\n2oHARWb2h+RCkoYBw4F9zGy1pCmE8m0AH5vZ+qwa7FxTZXmR4x7gYELP9XB8nCipE4CkbSV9CegK\nfBCDaxdg7wzb6FxVZdaDmdknkiYDy2Mv9IikrwHPxKKiq4ATgIeAsZLmAAuAaVm10blqyyzZN17c\neAE41sxeTXt/nuzr0pSrZF9J/YDXgMeyCC7n8iKrq4gvAjtmsa+CcrmInofostRsMzmcaw5yl00v\n6afAdwi/eW0ATgEuAXoBa+Jir5nZMbVpoXOVy1WASdoHOAzYw8zWSuoBbB5nH29mftXCNSu5CjBC\nL7XUzNYCmNlSgKKxwZxrNvJ2DvYI0FvSK5J+H0e4LLhZ0qz4uKzUyp6L6PImVz2Yma2SNAjYl1BO\n+0+Szomz6z1E9FxElze5CjCAmOUxBZgiaS4wqrYtcq7xcnWIKGlnSX0TkwYCi2vVHueaKm89WCfg\nSkndgHWE7I8xwJ2Ec7DCZfqlZja8Rm10rmJeeNS5RshVLqJzX1QeYM6lqMUGWCHZt1zxUeey0GID\nzLk8yE2ASVofszTmS5ot6cx4kyaShklakcjkmCXJryK63MvTZfo1haFiY22OW4AuwLlx/pNmdlit\nGudcY+SmB0sys/cIv3+dKs/0dc1YnnqwjZjZ67E89pfipH0lzUoscrSZLUyuE6sAjwFo1aVnNg11\nrg65DbAS6j1E9GRflze5PEQEkLQj4a7m92rdFucaK5cBJqknMAG4ylpqLpf7QsjTIWL7eI7VhpDo\n+0fg14n5xedgvzSzO7NsoHMNlZsAM7Oy432Z2RRCSe2K7bZtV6Z7iTZXY7k8RHSupfAAcy5FHmDO\npcgDzLkUeYA5lyIPMOdS5AHmXIo8wJxLkQeYcylqsWXbJK0kjPGcFz2ApbVuRIK3p351tWl7M6v3\nnqjcpEqlYEEldeuyImm6t6e8vLUHqtMmP0R0LkUeYM6lqCUH2MRaN6CIt6dueWsPVKFNLfYih3N5\n0JJ7MOdqzgPMuRS1uACTdLCkBZJeSww/m+X+e0uaLOnFWKX4tDh9vKS3EpWJR2TcrkWS5sZ9T4/T\nukt6VNKr8d8tMmrLzkVVmj+UdHqWn5Gk6yW9J2leYlrJz0PB7+J3ao6kPSrekZm1mAfQClgI7Ahs\nDswG+mXchl7AHvF5Z+AVoB8wHjirhp/NIqBH0bRLgXPi83OAS2r0f/YOsH2WnxGwH7AHMK++zwMY\nAfwVELA38Gyl+2lpPdgQ4DUze93MPgFuA47IsgFmtsTMXojPVwIvAdtm2YYGOAKYFJ9PAo6sQRsO\nBBaaWaZDBZvZE8D7RZPLfR5HADdaMA3oJqlXJftpaQG2LfBm4vXfqeGXW1IfYHfg2Tjp1HiIcX1W\nh2MJBjwiaUasgAywlZktic/fAbbKuE0AxwG3Jl7X8jMq93k0+nvV0gIsNyR1Au4CTjezD4FrgJ0I\nA7svAX6VcZOGmtkewCHADyTtl5xp4Vgo099sJG0OfBO4I06q9Wf0mWp9Hi0twN4CeidefzlOy5Sk\nNoTgutnM7gYws3fNbL2ZbQCuJRzOZsbM3or/vgfcE/f/buFQJ/6bdRXlQ4AXzOzd2LaafkaU/zwa\n/b1qaQH2PNBX0g7xr+NxwP1ZNiCOBvP/gJfM7NeJ6clj9qOAecXrptimjpI6F54DB8X93w+MiouN\nAu7Lqk3Rt0kcHtbyM4rKfR73A9+NVxP3BlYkDiXrlvVVowyuDo0gXLlbCPy0BvsfSji0mAPMio8R\nhErFc+P0+4FeGbZpR8IV1dnA/MLnAmwJPAa8CvwN6J5hmzoCy4CuiWmZfUaEwF4CfEo4pzqp3OdB\nuHp4dfxOzQUGV7ofT5VyLkUt7RDRuVzxAHMuRR5gzqXIA8y5FHmAOZciD7AmkrQ+Zn7Pk/RnSd0q\nWGdVPfO7Sfp+4vU2kpo82KCkPsns8SxIGpj1nQN54gHWdGvMbKCZ9Sckj/6gCtvsBnwWYGb2tpkd\nU4XtZkpSa0LakweYq4pnSCSBSvqxpOdj8uoviheW1EnSY5JeiPdqFTL/LwZ2ij3jZcmeR9I0Sbsm\ntjFF0uCYrXG9pOckzUxsqyRJoyXdG3vdNySdKulHcd1pkrontn+FpKdjLz0kTu8e158Tlx8Qp4+X\nNFHSI8CNwHnAyPheRkoaIumZuJ+nJe2caM/dkh6K92NdmmjrwfEzmi3psTitQe+3ZrLOdGhpD2BV\n/LcVIWn14Pj6IELRFBH+kD0A7Fe0TmugS3zeA3gtLt+Hje9T+uw1cAbwi/i8F6H+I8CFwAnxeTdC\nNkvHorYmtzM67q8z0BNYAYyN835DSFIGmAJcG5/vl1j/SuDc+PzrwKz4fDwwA2if2M9ViTZ0AVrH\n58OBuxLLvU4YKrgdsJiQ/9eTkMm+Q1yue6XvNw+Pllx4NCuFwdv7EL5Yj8bpB8XHzPi6E9AXeCKx\nroALY2b7BkLvV98tI7cDjwDnAt8CCudmBwHflHRWfN0O2I5wP1o5ky3cs7ZS0grgz3H6XGBAYrlb\nIdxDJalLPM8cChwdpz8uaUtJXeLy95vZmjL77ApMktSXkFLWJjHvMTNbASDpRcJNmFsAT5jZG3Ff\nhXu4GvN+M+cB1nRrzGygpK6EXuoHwO8IwXORmf2hjnWPJ/yFHmRmn0paRPiilGVmb0laFg/JRgJj\n4ywBR5tZQ8qFr00835B4vYGNvxvF+XT15dd9VMe88wmBfVS8X25Kmfasp+7vZ2Peb+b8HKxK4l/e\nccCZ8eT+YeDEeF8YkraV9KWi1boC78XgOoDwFxtgJeHQrZw/AWcTEmXnxGkPAz+M2fxI2r0a7ysa\nGbc5lJBJvgJ4kvAHAknDgKUW7nsrVvxeuvL5rR6jK9j3NGA/STvEfXWP09N8v1XjAVZFZjaTkAn+\nbTN7BLgFeEbSXMKhXHHQ3AwMVihCczzwctzOMmBqvKhwWYld3Um4Fef2xLTzCYdbcyTNj6+r5QNJ\nTwMTCFnnEM61BkmaQ7goM6rMupOBfoWLHIS6FxdJmko4b62Tmf0DGAPcLWk24Y8LpPt+q8az6V2d\nJE0hFKKZXuu2NEfegzmXIu/BnEuR92DOpcgDzLkUeYA5lyIPMOdS5AHmXIr+P/LavtRj4ErUAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5c1fdf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Did not help\n",
    "#df['age_bucket'] = df['agea'].apply(lambda x: 1 if x <= 20 else 2 if x <= 30 else 3 if x <= 40 else 4 if x <= 50 else 5 if x <=60 else 6 if x <= 70 else 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Did not help\n",
    "#df['young_or_old'] = df['agea'].apply(lambda x: 1 if x <= 20 else 1 if x >= 70 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>47687.771195</td>\n",
       "      <td>6.492918</td>\n",
       "      <td>3.864353</td>\n",
       "      <td>5.635149</td>\n",
       "      <td>6.062238</td>\n",
       "      <td>5.359266</td>\n",
       "      <td>7.905845</td>\n",
       "      <td>5.030521</td>\n",
       "      <td>2.747856</td>\n",
       "      <td>1.482944</td>\n",
       "      <td>50.979254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>28291.068283</td>\n",
       "      <td>6.512125</td>\n",
       "      <td>3.745373</td>\n",
       "      <td>5.478622</td>\n",
       "      <td>5.913848</td>\n",
       "      <td>5.261008</td>\n",
       "      <td>7.392789</td>\n",
       "      <td>5.512444</td>\n",
       "      <td>2.768985</td>\n",
       "      <td>1.517869</td>\n",
       "      <td>41.316528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 idno      year     tvtot   ppltrst   pplfair    pplhlp  \\\n",
       "partner                                                                   \n",
       "1.0      47687.771195  6.492918  3.864353  5.635149  6.062238  5.359266   \n",
       "2.0      28291.068283  6.512125  3.745373  5.478622  5.913848  5.261008   \n",
       "\n",
       "            happy   sclmeet    sclact      gndr       agea  \n",
       "partner                                                     \n",
       "1.0      7.905845  5.030521  2.747856  1.482944  50.979254  \n",
       "2.0      7.392789  5.512444  2.768985  1.517869  41.316528  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('partner').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looks like 'pplfair','ppltrst' and 'pplhlp' are pretty redundant with each\n",
    "# other. Let's make some averages. Just in case some of the variables are on\n",
    "# different scales than others (one ranges from 0 to 100, one ranges from 0 to\n",
    "# 7, for example) we scale them before averaging by subtracting the average of\n",
    "# each variable from all values in that variable, then dividing by the\n",
    "# standard deviation.\n",
    "\n",
    "means = df[['ppltrst','pplfair','pplhlp']].mean(axis=0)\n",
    "stds = df[['ppltrst','pplfair','pplhlp']].std(axis=0)\n",
    "df['trust_fair_help'] = ((df[['ppltrst','pplfair','pplhlp']] - means) / stds).mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03737043098745226\n",
      "Percent Type II errors: 0.1627114020731042\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06012269938650307\n",
      "Percent Type II errors: 0.17668711656441718\n"
     ]
    }
   ],
   "source": [
    "##Parameter tuning:\n",
    "#https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno', 'ppltrst','pplfair','pplhlp'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "#for depth in range(3):\n",
    "    #depth = depth + 2\n",
    "params = {'n_estimators': 5000,\n",
    "          #'max_depth': depth,\n",
    "            #'subsample' : 1,\n",
    "              'learning_rate' : 0.01,\n",
    "              'max_features' : 'sqrt',\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "    # Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "        #'Depth: {}\\n'\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.44949</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>7.745967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.44949</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>7.681146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.44949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.898979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.44949</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.44949</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>7.416198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year     tvtot   ppltrst   pplfair    pplhlp     happy   sclmeet  \\\n",
       "0  2.44949  1.732051  1.732051  3.162278  2.236068  2.828427  2.236068   \n",
       "1  2.44949  2.449490  2.236068  2.645751  2.236068  3.000000  1.732051   \n",
       "2  2.44949  1.000000  2.828427  2.828427  2.828427  2.645751  2.449490   \n",
       "3  2.44949  2.000000  2.449490  2.449490  2.645751  3.162278  2.449490   \n",
       "4  2.44949  2.236068  2.449490  2.645751  2.236068  2.828427  2.645751   \n",
       "\n",
       "     sclact      gndr      agea  \n",
       "0  2.000000  1.414214  7.745967  \n",
       "1  1.414214  1.414214  7.681146  \n",
       "2  1.732051  1.000000  4.898979  \n",
       "3  1.414214  1.414214  8.000000  \n",
       "4  1.414214  1.414214  7.416198  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note -- none of the below feature engineering sets improved performance - these are just pasted below for future reference\n",
    "\n",
    "\n",
    "#try transforming all variables (except the country ones) by sqrt, square, log, etc\n",
    "#transform the data into a normal distribution - boxcox? - actually only works for continuous output\n",
    "#try preprocessing standardizing the input variables mean 0 std 1\n",
    "#last resort: resample to see if distributions of input variables change significantly (can we make them more normal?) -\n",
    "#also speeds up algorithm\n",
    "    \n",
    "\n",
    "#Try transforming all variables (except the country ones) by SQRT, square, log, etc\n",
    "\n",
    "df2 = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "df2.head()\n",
    "df_sqrt = pd.DataFrame()\n",
    "for col in df2.columns:\n",
    "    df_sqrt[col] = np.sqrt(df2[col])\n",
    "df_sqrt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0463720676486634\n",
      "Percent Type II errors: 0.1729405346426623\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06993865030674846\n",
      "Percent Type II errors: 0.17914110429447852\n",
      "Depth: 3\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03436988543371522\n",
      "Percent Type II errors: 0.1498908892525914\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08220858895705521\n",
      "Percent Type II errors: 0.17791411042944785\n",
      "Depth: 4\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.017866884888161485\n",
      "Percent Type II errors: 0.10924713584288052\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08711656441717791\n",
      "Percent Type II errors: 0.18159509202453988\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df_sqrt.loc[:, ~df_sqrt.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "for depth in range(3):\n",
    "    depth = depth + 2\n",
    "    params = {'n_estimators': 5000,\n",
    "          'max_depth': depth,\n",
    "            'subsample' : 0.8,\n",
    "              'learning_rate' : 0.01,\n",
    "              #'max_features' : 1,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "    # Initialize and fit the model.\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "    print((\n",
    "        'Depth: {}\\n'\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(depth, train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3025.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr    agea\n",
       "0    36    9.0      9.0    100.0    25.0   64.0     25.0    16.0   4.0  3600.0\n",
       "1    36   36.0     25.0     49.0    25.0   81.0      9.0     4.0   4.0  3481.0\n",
       "2    36    1.0     64.0     64.0    64.0   49.0     36.0     9.0   1.0   576.0\n",
       "3    36   16.0     36.0     36.0    49.0  100.0     36.0     4.0   4.0  4096.0\n",
       "4    36   25.0     36.0     49.0    25.0   64.0     49.0     4.0   4.0  3025.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try transforming all variables (except the country ones) by sqrt, SQUARE, log, etc\n",
    "\n",
    "df2 = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "df2.head()\n",
    "df_square = pd.DataFrame()\n",
    "for col in df2.columns:\n",
    "    df_square[col] = (df2[col]) * (df2[col])\n",
    "df_square.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04732678668848882\n",
      "Percent Type II errors: 0.1762138570649209\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18650306748466258\n",
      "Depth: 3\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03764320785597381\n",
      "Percent Type II errors: 0.15384615384615385\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0785276073619632\n",
      "Percent Type II errors: 0.17914110429447852\n",
      "Depth: 4\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.01950354609929078\n",
      "Percent Type II errors: 0.12315875613747954\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09815950920245399\n",
      "Percent Type II errors: 0.17300613496932515\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df_square.loc[:, ~df_square.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "for depth in range(3):\n",
    "    depth = depth + 2\n",
    "    params = {'n_estimators': 5000,\n",
    "          'max_depth': depth,\n",
    "            #'subsample' : 1,\n",
    "              'learning_rate' : 0.01,\n",
    "              #'max_features' : 1,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "    # Initialize and fit the model.\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "    print((\n",
    "        'Depth: {}\\n'\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(depth, train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.094345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.94591</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.174387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.025352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year     tvtot   ppltrst   pplfair    pplhlp     happy   sclmeet  \\\n",
       "0  1.94591  1.386294  1.386294  2.397895  1.791759  2.197225  1.791759   \n",
       "1  1.94591  1.945910  1.791759  2.079442  1.791759  2.302585  1.386294   \n",
       "2  1.94591  0.693147  2.197225  2.197225  2.197225  2.079442  1.945910   \n",
       "3  1.94591  1.609438  1.945910  1.945910  2.079442  2.397895  1.945910   \n",
       "4  1.94591  1.791759  1.945910  2.079442  1.791759  2.197225  2.079442   \n",
       "\n",
       "     sclact      gndr      agea  \n",
       "0  1.609438  1.098612  4.110874  \n",
       "1  1.098612  1.098612  4.094345  \n",
       "2  1.386294  0.693147  3.218876  \n",
       "3  1.098612  1.098612  4.174387  \n",
       "4  1.098612  1.098612  4.025352  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try transforming all variables (except the country ones) by sqrt, square, LOG, etc\n",
    "\n",
    "df2 = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "df2.head()\n",
    "df_log = pd.DataFrame()\n",
    "for col in df2.columns:\n",
    "    ##SOME VALUES ARE ZERO, SO ADD 1 TO EVERYTHING TO AVOID DIVIDE BY ZERO ERROR FOR LOG\n",
    "    df_log[col] = np.log(df2[col] + 1)\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04732678668848882\n",
      "Percent Type II errors: 0.1762138570649209\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18650306748466258\n",
      "Depth: 3\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03764320785597381\n",
      "Percent Type II errors: 0.15384615384615385\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0785276073619632\n",
      "Percent Type II errors: 0.17914110429447852\n",
      "Depth: 4\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.01950354609929078\n",
      "Percent Type II errors: 0.12315875613747954\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09693251533742331\n",
      "Percent Type II errors: 0.17300613496932515\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df_log.loc[:, ~df_log.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "for depth in range(3):\n",
    "    depth = depth + 2\n",
    "    params = {'n_estimators': 5000,\n",
    "          'max_depth': depth,\n",
    "            #'subsample' : 1,\n",
    "              'learning_rate' : 0.01,\n",
    "              #'max_features' : 1,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "    # Initialize and fit the model.\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "    print((\n",
    "        'Depth: {}\\n'\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(depth, train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year     tvtot   ppltrst   pplfair    pplhlp     happy   sclmeet  \\\n",
       "0  0.142857  0.250000  0.250000  0.090909  0.166667  0.111111  0.166667   \n",
       "1  0.142857  0.142857  0.166667  0.125000  0.166667  0.100000  0.250000   \n",
       "2  0.142857  0.500000  0.111111  0.111111  0.111111  0.125000  0.142857   \n",
       "3  0.142857  0.200000  0.142857  0.142857  0.125000  0.090909  0.142857   \n",
       "4  0.142857  0.166667  0.142857  0.125000  0.166667  0.111111  0.125000   \n",
       "\n",
       "     sclact      gndr      agea  \n",
       "0  0.200000  0.333333  0.016393  \n",
       "1  0.333333  0.333333  0.016667  \n",
       "2  0.250000  0.500000  0.040000  \n",
       "3  0.333333  0.333333  0.015385  \n",
       "4  0.333333  0.333333  0.017857  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try transforming all variables (except the country ones) by sqrt, square, log, INVERSE\n",
    "\n",
    "df2 = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "df2.head()\n",
    "df_inv = pd.DataFrame()\n",
    "for col in df2.columns:\n",
    "    ##SOME VALUES ARE ZERO, SO ADD 1 TO EVERYTHING TO AVOID DIVIDE BY ZERO ERROR \n",
    "    df_inv[col] = 1/(df2[col] + 1)\n",
    "df_inv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04732678668848882\n",
      "Percent Type II errors: 0.1762138570649209\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18650306748466258\n",
      "Depth: 3\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03764320785597381\n",
      "Percent Type II errors: 0.15384615384615385\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0785276073619632\n",
      "Percent Type II errors: 0.17914110429447852\n",
      "Depth: 4\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.01950354609929078\n",
      "Percent Type II errors: 0.12315875613747954\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09815950920245399\n",
      "Percent Type II errors: 0.17300613496932515\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df_inv.loc[:, ~df_inv.columns.isin(['partner', 'cntry', 'idno', 'trust_fair_help'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "for depth in range(3):\n",
    "    depth = depth + 2\n",
    "    params = {'n_estimators': 5000,\n",
    "          'max_depth': depth,\n",
    "            #'subsample' : 1,\n",
    "              'learning_rate' : 0.01,\n",
    "              #'max_features' : 1,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "    # Initialize and fit the model.\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "    print((\n",
    "        'Depth: {}\\n'\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(depth, train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "59px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
